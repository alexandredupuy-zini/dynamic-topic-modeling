{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 15:06:28,895 - kedro.io.data_catalog - INFO - Loading data from `BOW_train` (ScipySparseMatrix)...\n",
      "2020-03-26 15:06:29,102 - kedro.io.data_catalog - INFO - Loading data from `UN_dictionary` (DictionaryDataSet)...\n",
      "2020-03-26 15:06:29,104 - gensim.utils - INFO - loading Dictionary object from data/05_model_input/UN_dictionary.dict\n",
      "2020-03-26 15:06:29,119 - gensim.utils - INFO - loaded data/05_model_input/UN_dictionary.dict\n",
      "2020-03-26 15:06:29,126 - kedro.io.data_catalog - INFO - Loading data from `Word_distribution` (NumpyArray)...\n"
     ]
    }
   ],
   "source": [
    "bow=catalog.load('BOW_train')\n",
    "vocab=catalog.load('UN_dictionary')\n",
    "beta=catalog.load('Word_distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the time it takes to calculate TC with two different technics : \n",
    "\n",
    "the first one is the one implemented on the DETM paper, we use it as a benchmark : we know it provides the good results, but it takes a very long time to fit.\n",
    "\n",
    "The second one is implemented by us, it is based on the direct Bag Of Words to calculate occurences & co occurences. We want to see if it provides the same results on a shorter fitting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal is to compare 2 way of calculating Topic Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. The first one is based on DETM paper implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_bow_2(bow_in, n_docs):\n",
    "    indices = [[w for w in bow_in[doc,:].indices] for doc in range(n_docs)]\n",
    "    indices_arr=[np.array(element) for element in indices]\n",
    "    counts = [[c for c in bow_in[doc,:].data] for doc in range(n_docs)]\n",
    "    counts_arr=[np.array(element) for element in counts]\n",
    "\n",
    "    return np.array(indices_arr), np.array(counts_arr)\n",
    "\n",
    "tokens,counts=split_bow_2(bow,bow.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_frequency(data, wi, wj=None):\n",
    "    if wj is None:\n",
    "        D_wi = 0\n",
    "        for l in range(len(data)):\n",
    "            #doc = data[l].squeeze(0)\n",
    "            #if len(doc) == 1: \n",
    "            #    continue\n",
    "                #doc = [doc.squeeze()]\n",
    "            #else:\n",
    "            #    doc = doc.squeeze()\n",
    "            if wi in data[l]:\n",
    "                D_wi += 1\n",
    "        return D_wi\n",
    "    D_wj = 0\n",
    "    D_wi_wj = 0\n",
    "    for l in range(len(data)):\n",
    "        #doc = data[l].squeeze(0)\n",
    "        #if len(doc) == 1: \n",
    "        #    doc = [doc.squeeze()]\n",
    "        #else:\n",
    "        #    doc = doc.squeeze()\n",
    "        if wj in data[l]:\n",
    "            D_wj += 1\n",
    "            if wi in data[l]:\n",
    "                D_wi_wj += 1\n",
    "    return D_wj, D_wi_wj \n",
    "\n",
    "\n",
    "def get_topic_coherence(data, beta, num_topics, num_coherence):\n",
    "\n",
    "    D = len(data) ## number of docs...data is list of documents\n",
    "    TC = []\n",
    "   \n",
    "    for k in range(num_topics):\n",
    "        print('\\tDone {}/{}'.format(k,num_topics))\n",
    "        top_10 = list(beta[k].argsort()[-num_coherence:][::-1])\n",
    "        #top_words = [vocab[a] for a in top_10]\n",
    "\n",
    "            \n",
    "        \n",
    "        TC_k = 0\n",
    "        counter = 0\n",
    "        for i, word in enumerate(top_10):\n",
    "            # get D(w_i)\n",
    "            D_wi = get_document_frequency(data, word)\n",
    "            p_wi=D_wi/D\n",
    "            j = i + 1\n",
    "            tmp = 0\n",
    "            while j < len(top_10) and j > i:\n",
    "                # get D(w_j) and D(w_i, w_j)\n",
    "                D_wj, D_wi_wj = get_document_frequency(data, word, top_10[j])\n",
    "                p_wj=D_wj/D\n",
    "                p_wi_wj=D_wi_wj/D\n",
    "\n",
    "                if D_wi_wj == 0 :\n",
    "                    tc_pairwise=-1\n",
    "                elif D_wi_wj==D_wi and D_wi_wj==D_wj : \n",
    "                    tc_pairwise=1\n",
    "                # get f(w_i, w_j)\n",
    "                else : \n",
    "                    tc_pairwise = np.log(p_wi_wj/(p_wi*p_wj))/-np.log(p_wi_wj)\n",
    "\n",
    "                # update tmp: \n",
    "\n",
    "                tmp += tc_pairwise\n",
    "                j += 1\n",
    "                counter += 1\n",
    "            # update TC_k\n",
    "            TC_k += tmp \n",
    "        TC_k=TC_k/counter\n",
    "        TC.append(TC_k)\n",
    "    print(TC)    \n",
    "    #TC = np.mean(TC) / counter\n",
    "    return TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topic_coherence(data,beta,num_times,num_topics,num_coherence=6) : \n",
    "    \n",
    "    tc=np.zeros((num_times,num_topics))\n",
    "    \n",
    "    times=[]\n",
    "    for timestep in range(num_times): \n",
    "        t0=time()\n",
    "\n",
    "        print('-'*100)\n",
    "        print('Timestep {}/{}'.format(timestep,num_times))\n",
    "        print('-'*100)\n",
    "        print('\\n')\n",
    "        tc[timestep,:]=get_topic_coherence(data,beta[:,timestep,:],num_topics,num_coherence)\n",
    "        \n",
    "        fitting_time=time()-t0\n",
    "        \n",
    "        print('\\nFitting time : {}s\\n'.format(round(fitting_time,2)))\n",
    "        \n",
    "        times.append(fitting_time)\n",
    "    total_time=round(np.sum(times),2)\n",
    "    print('Total fitting time for {} timestep & {} number of words is : {}s'.format(num_times,num_coherence,total_time))\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents : 6382\n",
      "Total number of words : 10812\n",
      "Test number of timestep : 10\n",
      "Test number of words to calcualte co occurences : 10\n"
     ]
    }
   ],
   "source": [
    "test_number_of_times=10\n",
    "test_number_of_words=10\n",
    "\n",
    "print('Total number of documents : {}'.format(bow.shape[0]))\n",
    "print('Total number of words : {}'.format(bow.shape[1]))\n",
    "print('Test number of timestep : {}'.format(test_number_of_times))\n",
    "print('Test number of words to calcualte co occurences : {}'.format(test_number_of_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 0/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.033995217221109944, 0.04215773577567638]\n",
      "\n",
      "Fitting time : 5.02s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 1/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.11902849862264936, 0.043468405456986756]\n",
      "\n",
      "Fitting time : 5.2s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 2/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.08711458931198925, 0.07574572358603056]\n",
      "\n",
      "Fitting time : 4.96s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 3/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.06410442751847617, 0.07755731623635759]\n",
      "\n",
      "Fitting time : 5.03s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 4/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.1066199097256686, 0.09863093014448084]\n",
      "\n",
      "Fitting time : 4.83s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 5/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.09884464376128596, 0.11751429311908132]\n",
      "\n",
      "Fitting time : 5.1s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 6/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.13676234924202094, 0.06035407570119014]\n",
      "\n",
      "Fitting time : 5.19s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 7/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.12208613010067655, 0.10098747939931148]\n",
      "\n",
      "Fitting time : 5.19s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 8/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.07004845640879456, 0.11633655543670116]\n",
      "\n",
      "Fitting time : 5.32s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 9/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.14564322602478086, 0.06052879367886548]\n",
      "\n",
      "Fitting time : 5.29s\n",
      "\n",
      "Total fitting time for 10 timestep & 10 number of words is : 51.14s\n"
     ]
    }
   ],
   "source": [
    "test_1=model_topic_coherence(tokens,beta,test_number_of_times,2,test_number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Topic Coherence : \n",
      "[[0.03399522 0.04215774]\n",
      " [0.1190285  0.04346841]\n",
      " [0.08711459 0.07574572]\n",
      " [0.06410443 0.07755732]\n",
      " [0.10661991 0.09863093]\n",
      " [0.09884464 0.11751429]\n",
      " [0.13676235 0.06035408]\n",
      " [0.12208613 0.10098748]\n",
      " [0.07004846 0.11633656]\n",
      " [0.14564323 0.06052879]]\n"
     ]
    }
   ],
   "source": [
    "print('Final Topic Coherence : ')\n",
    "print(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Based on BOW representation of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_freq(bow,wi,wj=None): \n",
    "    if wj is None : \n",
    "        return bow[:,wi].sum(axis=0)\n",
    "    new=bow[:,wi]+bow[:,wj]\n",
    "    return bow[:,wj].sum(axis=0),new[new==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_bow(bow) :\n",
    "    \"\"\"This function takes in input a basic BOW such as CountVecotrizer BOWs and return a one-hot BOW. This is a BOW where \n",
    "       each element (i,j) of the matrix is either a 0 if the word j is not in document i, and 1 if word j is in doc j.\n",
    "       This differs from original BOW as in these standard BOW, each element (i,j) of the matrix is either 0 if the word j \n",
    "       is in document i or n_occu where n_occu is an integer that represents the number of times the word j appears in document i\"\"\"\n",
    "    t0=time()\n",
    "    \n",
    "    bow_new=np.zeros((bow.shape[0],bow.shape[1]))\n",
    "    for idx in range(bow.shape[0]) : \n",
    "        for i in np.argwhere(bow[idx]) :\n",
    "            bow_new[idx,i[1]]=1\n",
    "    print('Fitting time is : {}s'.format(round(time()-t0,2)))\n",
    "    return bow_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time is : 4.31s\n"
     ]
    }
   ],
   "source": [
    "bow_test=get_one_hot_bow(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_coherence_2(data, beta, num_topics, num_coherence):\n",
    "\n",
    "    D = len(data) ## number of docs...data is list of documents\n",
    "    TC = []\n",
    "   \n",
    "    for k in range(num_topics):\n",
    "        print('\\tDone {}/{}'.format(k,num_topics))\n",
    "        top_10 = list(beta[k].argsort()[-num_coherence:][::-1])\n",
    "        #top_words = [vocab[a] for a in top_10]\n",
    "\n",
    "            \n",
    "        \n",
    "        TC_k = 0\n",
    "        counter = 0\n",
    "        for i, word in enumerate(top_10):\n",
    "            # get D(w_i)\n",
    "            D_wi = get_doc_freq(data, word)\n",
    "            p_wi=D_wi/D\n",
    "            j = i + 1\n",
    "            tmp = 0\n",
    "            while j < len(top_10) and j > i:\n",
    "                # get D(w_j) and D(w_i, w_j)\n",
    "                D_wj, D_wi_wj = get_doc_freq(data, word, top_10[j])\n",
    "                p_wj=D_wj/D\n",
    "                p_wi_wj=D_wi_wj/D\n",
    "\n",
    "                if D_wi_wj == 0 :\n",
    "                    tc_pairwise=-1\n",
    "                elif D_wi_wj==D_wi and D_wi_wj==D_wj : \n",
    "                    tc_pairwise=1\n",
    "                # get f(w_i, w_j)\n",
    "                else : \n",
    "                    tc_pairwise = np.log(p_wi_wj/(p_wi*p_wj))/-np.log(p_wi_wj)\n",
    "\n",
    "                # update tmp: \n",
    "\n",
    "                tmp += tc_pairwise\n",
    "                j += 1\n",
    "                counter += 1\n",
    "            # update TC_k\n",
    "            TC_k += tmp \n",
    "        TC_k=TC_k/counter\n",
    "        TC.append(TC_k)\n",
    "    print(TC)    \n",
    "    #TC = np.mean(TC) / counter\n",
    "    return TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topic_coherence_2(data,beta,num_times,num_topics,num_coherence=6) : \n",
    "    \n",
    "\n",
    "    tc=np.zeros((num_times,num_topics))\n",
    "    \n",
    "    times=[]\n",
    "    for timestep in range(num_times): \n",
    "        t0=time()\n",
    "\n",
    "        print('-'*100)\n",
    "        print('Timestep {}/{}'.format(timestep,num_times))\n",
    "        print('-'*100)\n",
    "        print('\\n')\n",
    "        tc[timestep,:]=get_topic_coherence_2(data,beta[:,timestep,:],num_topics,num_coherence)\n",
    "        \n",
    "        fitting_time=time()-t0\n",
    "        \n",
    "        print('\\nFitting time : {}s\\n'.format(round(fitting_time,2)))\n",
    "        \n",
    "        times.append(fitting_time)\n",
    "    total_time=round(np.sum(times),2)\n",
    "    print('Total fitting time for {} timestep & {} number of words is : {}s'.format(num_times,num_coherence,total_time))\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 0/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.033995217221109944, 0.04215773577567638]\n",
      "\n",
      "Fitting time : 0.07s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 1/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.11902849862264936, 0.043468405456986756]\n",
      "\n",
      "Fitting time : 0.07s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 2/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.08711458931198925, 0.07574572358603056]\n",
      "\n",
      "Fitting time : 0.07s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 3/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.06410442751847617, 0.07755731623635759]\n",
      "\n",
      "Fitting time : 0.07s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 4/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.1066199097256686, 0.09863093014448084]\n",
      "\n",
      "Fitting time : 0.08s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 5/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.09884464376128596, 0.11751429311908132]\n",
      "\n",
      "Fitting time : 0.07s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 6/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.13676234924202094, 0.06035407570119014]\n",
      "\n",
      "Fitting time : 0.08s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 7/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.12208613010067655, 0.10098747939931148]\n",
      "\n",
      "Fitting time : 0.08s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 8/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.07004845640879456, 0.11633655543670116]\n",
      "\n",
      "Fitting time : 0.08s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 9/10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.14564322602478086, 0.06052879367886548]\n",
      "\n",
      "Fitting time : 0.08s\n",
      "\n",
      "Total fitting time for 10 timestep & 10 number of words is : 0.73s\n"
     ]
    }
   ],
   "source": [
    "test_2=model_topic_coherence_2(bow_test,beta,test_number_of_times,2,test_number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Topic Coherence : \n",
      "[[0.03399522 0.04215774]\n",
      " [0.1190285  0.04346841]\n",
      " [0.08711459 0.07574572]\n",
      " [0.06410443 0.07755732]\n",
      " [0.10661991 0.09863093]\n",
      " [0.09884464 0.11751429]\n",
      " [0.13676235 0.06035408]\n",
      " [0.12208613 0.10098748]\n",
      " [0.07004846 0.11633656]\n",
      " [0.14564323 0.06052879]]\n"
     ]
    }
   ],
   "source": [
    "print('Final Topic Coherence : ')\n",
    "print(test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC with method 1 :\n",
      "[[0.03399522 0.04215774]\n",
      " [0.1190285  0.04346841]\n",
      " [0.08711459 0.07574572]\n",
      " [0.06410443 0.07755732]\n",
      " [0.10661991 0.09863093]\n",
      " [0.09884464 0.11751429]\n",
      " [0.13676235 0.06035408]\n",
      " [0.12208613 0.10098748]\n",
      " [0.07004846 0.11633656]\n",
      " [0.14564323 0.06052879]]\n",
      "\n",
      "\tFitting time : 51.14s\n",
      "\n",
      "\n",
      "TC with method 2 :\n",
      "[[0.03399522 0.04215774]\n",
      " [0.1190285  0.04346841]\n",
      " [0.08711459 0.07574572]\n",
      " [0.06410443 0.07755732]\n",
      " [0.10661991 0.09863093]\n",
      " [0.09884464 0.11751429]\n",
      " [0.13676235 0.06035408]\n",
      " [0.12208613 0.10098748]\n",
      " [0.07004846 0.11633656]\n",
      " [0.14564323 0.06052879]]\n",
      "\n",
      "\tFitting time : 4.31s for creating one-hot-BOW, 0.73s for fitting time\n"
     ]
    }
   ],
   "source": [
    "print('TC with method 1 :')\n",
    "print(test_1)\n",
    "print('\\n\\tFitting time : 51.14s')\n",
    "print('\\n')\n",
    "print('TC with method 2 :')\n",
    "print(test_2)\n",
    "print('\\n\\tFitting time : 4.31s for creating one-hot-BOW, 0.73s for fitting time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the exact same results and divided the time of fitting by 10 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An other way to benchmark : varying the number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_number_of_words=30\n",
    "test_number_of_times=3 #We reduce this in order to get less total computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 0/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.03952746930657039, 0.04122628159712735]\n",
      "\n",
      "Fitting time : 43.04s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 1/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.0527796056484553, 0.06979573092922156]\n",
      "\n",
      "Fitting time : 42.04s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 2/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.08259622498258, 0.07429565904991407]\n",
      "\n",
      "Fitting time : 45.07s\n",
      "\n",
      "Total fitting time for 3 timestep & 30 number of words is : 130.15s\n"
     ]
    }
   ],
   "source": [
    "test_1_=model_topic_coherence(tokens,beta,test_number_of_times,2,test_number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Topic Coherence : \n",
      "[[0.03952747 0.04122628]\n",
      " [0.05277961 0.06979573]\n",
      " [0.08259622 0.07429566]]\n"
     ]
    }
   ],
   "source": [
    "print('Final Topic Coherence : ')\n",
    "print(test_1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 0/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.03952746930657039, 0.04122628159712735]\n",
      "\n",
      "Fitting time : 0.33s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 1/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.0527796056484553, 0.06979573092922156]\n",
      "\n",
      "Fitting time : 0.33s\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Timestep 2/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tDone 0/2\n",
      "\tDone 1/2\n",
      "[0.08259622498258, 0.07429565904991407]\n",
      "\n",
      "Fitting time : 0.37s\n",
      "\n",
      "Total fitting time for 3 timestep & 30 number of words is : 1.03s\n"
     ]
    }
   ],
   "source": [
    "test_2_=model_topic_coherence_2(bow_test,beta,test_number_of_times,2,test_number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Topic Coherence : \n",
      "[[0.03952747 0.04122628]\n",
      " [0.05277961 0.06979573]\n",
      " [0.08259622 0.07429566]]\n"
     ]
    }
   ],
   "source": [
    "print('Final Topic Coherence : ')\n",
    "print(test_2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC with method 1 :\n",
      "[[0.03952747 0.04122628]\n",
      " [0.05277961 0.06979573]\n",
      " [0.08259622 0.07429566]]\n",
      "\n",
      "\tFitting time : 130.15s\n",
      "\n",
      "\n",
      "TC with method 2 :\n",
      "[[0.03952747 0.04122628]\n",
      " [0.05277961 0.06979573]\n",
      " [0.08259622 0.07429566]]\n",
      "\n",
      "\tFitting time : 4.31s for creating one-hot-BOW, 1.03s for fitting time\n"
     ]
    }
   ],
   "source": [
    "print('TC with method 1 :')\n",
    "print(test_1_)\n",
    "print('\\n\\tFitting time : 130.15s')\n",
    "print('\\n')\n",
    "print('TC with method 2 :')\n",
    "print(test_2_)\n",
    "print('\\n\\tFitting time : 4.31s for creating one-hot-BOW, 1.03s for fitting time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method we implemented seems clearly better, as it takes 130 times less computational time to compute for 30 words. As the number of words increases, the advantage of our technic is exploding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DynamicTopicModeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
