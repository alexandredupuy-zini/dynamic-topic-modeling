# Parameters of the pipeline "Data processing"

## Parameters of the node "Get data"
dataset: '20NG' # 20NG, UNGD, SOGE

## Parameters of the node "Preprocess data"
#language: english
flag_word_analysis: True #Boolean, set to True if you want to print some basic word anaylis (basically the number of words removed from each preprocces steps.)
flag_split_by_paragraph: False
flag_lemmatize: True
flag_bigram: False # Boolean, decide if you want bigrams or not in the dictionary
min_bigram_count: 20 #Int, threshold for bigrams :  Bigram will be added to the dictionary if in more than min_bigram_count documents

## Parameters of the node "Split data"
test_size: 0.05
val_size: 0.15
extreme_no_below: 100 #if >1 : for a word w, delete this word from vocabulary if w in less than extreme_no_below documents. if in [0,1], for a word w, delete this word from vocabulary if w in less than extreme_no_below% documents
extreme_no_above: 0.7 #in [0,1], for a word w, delete this word from vocabulary if w in more than extreme_no_below% documents



# Parameters of the pipeline "Machine Learning"

## Parameters of the node "Train model"
num_topics: 15
epochs: 100

#model: 'LDA'

#model: 'ETM'
flag_pretrained_embeddings: True
flag_finetune_embeddings: False
embedding_size: 300

#model: 'word2vec+kmeans'


## Parameters of the node "Evaluate model"
top_n_show: 10
m_most: 1
top_n_coherence: 10 # Number of words to take account of when computing coherence.
top_n_diversity : 25 # Number of words to take account of when computing diversity.
